{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from  pyod.models.knn import KNN\n",
    "from pyod.models.auto_encoder import AutoEncoder\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data=pd.read_csv(\"ProcessedData.csv\",encoding=\"latin1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>device</th>\n",
       "      <th>smoothed_temperature</th>\n",
       "      <th>smoothed_pressure</th>\n",
       "      <th>smoothed_waterFraction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/1/2010 0:00</td>\n",
       "      <td>42001</td>\n",
       "      <td>0.419956</td>\n",
       "      <td>2.297892</td>\n",
       "      <td>1.342423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1/1/2010 1:00</td>\n",
       "      <td>42001</td>\n",
       "      <td>0.438078</td>\n",
       "      <td>2.312392</td>\n",
       "      <td>1.342423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1/1/2010 2:00</td>\n",
       "      <td>42001</td>\n",
       "      <td>0.462535</td>\n",
       "      <td>2.326438</td>\n",
       "      <td>1.380211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1/1/2010 3:00</td>\n",
       "      <td>42001</td>\n",
       "      <td>0.570786</td>\n",
       "      <td>2.600585</td>\n",
       "      <td>1.397940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1/1/2010 4:00</td>\n",
       "      <td>42001</td>\n",
       "      <td>0.570786</td>\n",
       "      <td>2.674917</td>\n",
       "      <td>1.623249</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            date  device  smoothed_temperature  smoothed_pressure  \\\n",
       "0  1/1/2010 0:00   42001              0.419956           2.297892   \n",
       "1  1/1/2010 1:00   42001              0.438078           2.312392   \n",
       "2  1/1/2010 2:00   42001              0.462535           2.326438   \n",
       "3  1/1/2010 3:00   42001              0.570786           2.600585   \n",
       "4  1/1/2010 4:00   42001              0.570786           2.674917   \n",
       "\n",
       "   smoothed_waterFraction  \n",
       "0                1.342423  \n",
       "1                1.342423  \n",
       "2                1.380211  \n",
       "3                1.397940  \n",
       "4                1.623249  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data.drop(columns={'date','device'},axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5028 entries, 0 to 5027\n",
      "Data columns (total 3 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   smoothed_temperature    5028 non-null   float64\n",
      " 1   smoothed_pressure       5028 non-null   float64\n",
      " 2   smoothed_waterFraction  5028 non-null   float64\n",
      "dtypes: float64(3)\n",
      "memory usage: 118.0 KB\n"
     ]
    }
   ],
   "source": [
    "processed_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train =StandardScaler().fit_transform(X_train)\n",
    "X_train =pd.DataFrame(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 3)                 12        \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 3)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 12        \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 3)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 12        \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 3)                 0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 4         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 1)                 0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 2         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 1)                 0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 3)                 6         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 3)                 0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 3)                 12        \n",
      "=================================================================\n",
      "Total params: 60\n",
      "Trainable params: 60\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 1.5324 - val_loss: 1.4322\n",
      "Epoch 2/100\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 1.3815 - val_loss: 1.3307\n",
      "Epoch 3/100\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 1.2940 - val_loss: 1.2652\n",
      "Epoch 4/100\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 1.2354 - val_loss: 1.2185\n",
      "Epoch 5/100\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 1.1936 - val_loss: 1.1839\n",
      "Epoch 6/100\n",
      "142/142 [==============================] - 0s 1ms/step - loss: 1.1622 - val_loss: 1.1573\n",
      "Epoch 7/100\n",
      "142/142 [==============================] - 0s 1ms/step - loss: 1.1377 - val_loss: 1.1362\n",
      "Epoch 8/100\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 1.1183 - val_loss: 1.1192\n",
      "Epoch 9/100\n",
      "142/142 [==============================] - 0s 1ms/step - loss: 1.1024 - val_loss: 1.1051\n",
      "Epoch 10/100\n",
      "142/142 [==============================] - 0s 1ms/step - loss: 1.0892 - val_loss: 1.0933\n",
      "Epoch 11/100\n",
      "142/142 [==============================] - 0s 1ms/step - loss: 1.0782 - val_loss: 1.0834\n",
      "Epoch 12/100\n",
      "142/142 [==============================] - 0s 1ms/step - loss: 1.0688 - val_loss: 1.0750\n",
      "Epoch 13/100\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 1.0609 - val_loss: 1.0678\n",
      "Epoch 14/100\n",
      "142/142 [==============================] - 0s 1ms/step - loss: 1.0541 - val_loss: 1.0616\n",
      "Epoch 15/100\n",
      "142/142 [==============================] - 0s 1ms/step - loss: 1.0482 - val_loss: 1.0562\n",
      "Epoch 16/100\n",
      "142/142 [==============================] - 0s 1ms/step - loss: 1.0431 - val_loss: 1.0516\n",
      "Epoch 17/100\n",
      "142/142 [==============================] - 0s 1ms/step - loss: 1.0387 - val_loss: 1.0476\n",
      "Epoch 18/100\n",
      "142/142 [==============================] - 0s 1ms/step - loss: 1.0348 - val_loss: 1.0440\n",
      "Epoch 19/100\n",
      "142/142 [==============================] - 0s 1ms/step - loss: 1.0314 - val_loss: 1.0409\n",
      "Epoch 20/100\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 1.0284 - val_loss: 1.0381\n",
      "Epoch 21/100\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 1.0258 - val_loss: 1.0356\n",
      "Epoch 22/100\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 1.0234 - val_loss: 1.0335\n",
      "Epoch 23/100\n",
      "142/142 [==============================] - 0s 1ms/step - loss: 1.0213 - val_loss: 1.0315\n",
      "Epoch 24/100\n",
      "142/142 [==============================] - 0s 1ms/step - loss: 1.0194 - val_loss: 1.0298\n",
      "Epoch 25/100\n",
      "142/142 [==============================] - 0s 1ms/step - loss: 1.0177 - val_loss: 1.0282\n",
      "Epoch 26/100\n",
      "142/142 [==============================] - 0s 1ms/step - loss: 1.0161 - val_loss: 1.0268\n",
      "Epoch 27/100\n",
      "142/142 [==============================] - 0s 1ms/step - loss: 1.0147 - val_loss: 1.0255\n",
      "Epoch 28/100\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 1.0135 - val_loss: 1.0243\n",
      "Epoch 29/100\n",
      "142/142 [==============================] - 0s 1ms/step - loss: 1.0124 - val_loss: 1.0233\n",
      "Epoch 30/100\n",
      "142/142 [==============================] - 0s 1ms/step - loss: 1.0113 - val_loss: 1.0224\n",
      "Epoch 31/100\n",
      "142/142 [==============================] - 0s 1ms/step - loss: 1.0104 - val_loss: 1.0215\n",
      "Epoch 32/100\n",
      "142/142 [==============================] - 0s 1ms/step - loss: 1.0095 - val_loss: 1.0207\n",
      "Epoch 33/100\n",
      "142/142 [==============================] - 0s 1ms/step - loss: 1.0088 - val_loss: 1.0200\n",
      "Epoch 34/100\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 1.0081 - val_loss: 1.0193\n",
      "Epoch 35/100\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 1.0074 - val_loss: 1.0187\n",
      "Epoch 36/100\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 1.0068 - val_loss: 1.0182\n",
      "Epoch 37/100\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 1.0063 - val_loss: 1.0177\n",
      "Epoch 38/100\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 1.0058 - val_loss: 1.0172\n",
      "Epoch 39/100\n",
      "142/142 [==============================] - 0s 1ms/step - loss: 1.0053 - val_loss: 1.0168\n",
      "Epoch 40/100\n",
      "142/142 [==============================] - 0s 1ms/step - loss: 1.0049 - val_loss: 1.0164\n",
      "Epoch 41/100\n",
      "142/142 [==============================] - 0s 1ms/step - loss: 1.0045 - val_loss: 1.0160\n",
      "Epoch 42/100\n",
      "142/142 [==============================] - 0s 1ms/step - loss: 1.0041 - val_loss: 1.0157\n",
      "Epoch 43/100\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 1.0038 - val_loss: 1.0154\n",
      "Epoch 44/100\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 1.0035 - val_loss: 1.0151\n",
      "Epoch 45/100\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 1.0032 - val_loss: 1.0149\n",
      "Epoch 46/100\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 1.0029 - val_loss: 1.0146\n",
      "Epoch 47/100\n",
      "142/142 [==============================] - 0s 1ms/step - loss: 1.0027 - val_loss: 1.0144\n",
      "Epoch 48/100\n",
      "142/142 [==============================] - 0s 1ms/step - loss: 1.0024 - val_loss: 1.0142\n",
      "Epoch 49/100\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 1.0022 - val_loss: 1.0140\n",
      "Epoch 50/100\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 1.0020 - val_loss: 1.0138\n",
      "Epoch 51/100\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 1.0019 - val_loss: 1.0137\n",
      "Epoch 52/100\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 1.0017 - val_loss: 1.0135\n",
      "Epoch 53/100\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 1.0015 - val_loss: 1.0134\n",
      "Epoch 54/100\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 1.0014 - val_loss: 1.0132\n",
      "Epoch 55/100\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 1.0012 - val_loss: 1.0131\n",
      "Epoch 56/100\n",
      "142/142 [==============================] - 0s 1ms/step - loss: 1.0011 - val_loss: 1.0130\n",
      "Epoch 57/100\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 1.0010 - val_loss: 1.0129\n",
      "Epoch 58/100\n",
      "142/142 [==============================] - 0s 1ms/step - loss: 1.0009 - val_loss: 1.0128\n",
      "Epoch 59/100\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 1.0008 - val_loss: 1.0127\n",
      "Epoch 60/100\n",
      "142/142 [==============================] - 0s 1ms/step - loss: 1.0007 - val_loss: 1.0126\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142/142 [==============================] - 0s 2ms/step - loss: 1.0006 - val_loss: 1.0125\n",
      "Epoch 62/100\n",
      "142/142 [==============================] - 0s 1ms/step - loss: 1.0005 - val_loss: 1.0124\n",
      "Epoch 63/100\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 1.0004 - val_loss: 1.0124\n",
      "Epoch 64/100\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 1.0003 - val_loss: 1.0123\n",
      "Epoch 65/100\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 1.0002 - val_loss: 1.0122\n",
      "Epoch 66/100\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 1.0002 - val_loss: 1.0122\n",
      "Epoch 67/100\n",
      "142/142 [==============================] - 0s 1ms/step - loss: 1.0001 - val_loss: 1.0121\n",
      "Epoch 68/100\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 1.0001 - val_loss: 1.0121\n",
      "Epoch 69/100\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 1.0000 - val_loss: 1.0120\n",
      "Epoch 70/100\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 0.9999 - val_loss: 1.0120\n",
      "Epoch 71/100\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 0.9999 - val_loss: 1.0119\n",
      "Epoch 72/100\n",
      "142/142 [==============================] - 0s 1ms/step - loss: 0.9998 - val_loss: 1.0119\n",
      "Epoch 73/100\n",
      "142/142 [==============================] - 0s 1ms/step - loss: 0.9998 - val_loss: 1.0118\n",
      "Epoch 74/100\n",
      "142/142 [==============================] - 0s 1ms/step - loss: 0.9998 - val_loss: 1.0118\n",
      "Epoch 75/100\n",
      "142/142 [==============================] - 0s 1ms/step - loss: 0.9997 - val_loss: 1.0118\n",
      "Epoch 76/100\n",
      "142/142 [==============================] - 0s 1ms/step - loss: 0.9997 - val_loss: 1.0117\n",
      "Epoch 77/100\n",
      "142/142 [==============================] - 0s 1ms/step - loss: 0.9996 - val_loss: 1.0117\n",
      "Epoch 78/100\n",
      "142/142 [==============================] - 0s 1ms/step - loss: 0.9996 - val_loss: 1.0117\n",
      "Epoch 79/100\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 0.9996 - val_loss: 1.0116\n",
      "Epoch 80/100\n",
      "142/142 [==============================] - 0s 1ms/step - loss: 0.9995 - val_loss: 1.0116\n",
      "Epoch 81/100\n",
      "142/142 [==============================] - 0s 1ms/step - loss: 0.9995 - val_loss: 1.0116\n",
      "Epoch 82/100\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 0.9995 - val_loss: 1.0116\n",
      "Epoch 83/100\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 0.9995 - val_loss: 1.0115\n",
      "Epoch 84/100\n",
      "142/142 [==============================] - 0s 1ms/step - loss: 0.9994 - val_loss: 1.0115\n",
      "Epoch 85/100\n",
      "142/142 [==============================] - 0s 1ms/step - loss: 0.9994 - val_loss: 1.0115\n",
      "Epoch 86/100\n",
      "142/142 [==============================] - 0s 1ms/step - loss: 0.9994 - val_loss: 1.0115\n",
      "Epoch 87/100\n",
      "142/142 [==============================] - 0s 1ms/step - loss: 0.9994 - val_loss: 1.0115\n",
      "Epoch 88/100\n",
      "142/142 [==============================] - 0s 1ms/step - loss: 0.9993 - val_loss: 1.0115\n",
      "Epoch 89/100\n",
      "142/142 [==============================] - 0s 1ms/step - loss: 0.9993 - val_loss: 1.0114\n",
      "Epoch 90/100\n",
      "142/142 [==============================] - 0s 1ms/step - loss: 0.9993 - val_loss: 1.0114\n",
      "Epoch 91/100\n",
      "142/142 [==============================] - 0s 1ms/step - loss: 0.9993 - val_loss: 1.0114\n",
      "Epoch 92/100\n",
      "142/142 [==============================] - 0s 1ms/step - loss: 0.9993 - val_loss: 1.0114\n",
      "Epoch 93/100\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 0.9993 - val_loss: 1.0114\n",
      "Epoch 94/100\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 0.9992 - val_loss: 1.0114\n",
      "Epoch 95/100\n",
      "142/142 [==============================] - 0s 1ms/step - loss: 0.9992 - val_loss: 1.0114\n",
      "Epoch 96/100\n",
      "142/142 [==============================] - 0s 1ms/step - loss: 0.9992 - val_loss: 1.0113\n",
      "Epoch 97/100\n",
      "142/142 [==============================] - 0s 1ms/step - loss: 0.9992 - val_loss: 1.0113\n",
      "Epoch 98/100\n",
      "142/142 [==============================] - 0s 1ms/step - loss: 0.9992 - val_loss: 1.0113\n",
      "Epoch 99/100\n",
      "142/142 [==============================] - 0s 1ms/step - loss: 0.9992 - val_loss: 1.0113\n",
      "Epoch 100/100\n",
      "142/142 [==============================] - 0s 1ms/step - loss: 0.9992 - val_loss: 1.0113\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AutoEncoder(batch_size=32, contamination=0.1, dropout_rate=0.2, epochs=100,\n",
       "      hidden_activation='relu', hidden_neurons=[3, 1, 1, 3],\n",
       "      l2_regularizer=0.1,\n",
       "      loss=<function mean_squared_error at 0x000001ACD2898E18>,\n",
       "      optimizer='adam', output_activation='sigmoid', preprocessing=True,\n",
       "      random_state=None, validation_size=0.1, verbose=1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf1 = AutoEncoder(hidden_neurons =[3, 1, 1, 3])\n",
    "clf1.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.1899363725586727"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the outlier scores for the train data\n",
    "y_train_scores = clf1.decision_scores_  \n",
    "y_train_scores[128]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "td=pd.read_csv(\"test.csv\",encoding=\"latin1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=td"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test  =StandardScaler().fit_transform(X_test)\n",
    "X_test  =pd.DataFrame(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Predict the anomaly scores\n",
    "y_test_scores = clf1.decision_function(X_test)  # outlier scores\n",
    "y_test_scores = pd.Series(y_test_scores)\n",
    "\n",
    "# Plot it!\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(y_test_scores, bins='auto')  \n",
    "plt.title(\"Histogram for Model Clf1 Anomaly Scores\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
